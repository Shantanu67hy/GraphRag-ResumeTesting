{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d5add4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install neo4j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06890560",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install neo4j-graphrag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c839a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install neo4j-graphrag[openai]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a7139d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd289c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This example demonstrates how to use SimpleKGPipeline with automatic schema extraction\n",
    "from a PDF file. When no schema is provided to SimpleKGPipeline, automatic schema extraction\n",
    "is performed using the LLM.\n",
    "\n",
    "Note: This example requires an OpenAI API key to be set in the .env file.\n",
    "\"\"\"\n",
    "\n",
    "import neo4j\n",
    "from neo4j_graphrag.retrievers import VectorRetriever\n",
    "from neo4j_graphrag.generation.graphrag import GraphRAG\n",
    "from neo4j import GraphDatabase\n",
    "from neo4j_graphrag.embeddings import AzureOpenAIEmbeddings\n",
    "from neo4j_graphrag.experimental.pipeline.kg_builder import SimpleKGPipeline\n",
    "from neo4j_graphrag.llm import AzureOpenAILLM\n",
    "from neo4j_graphrag.experimental.components.text_splitters.fixed_size_splitter import FixedSizeSplitter\n",
    "from neo4j_graphrag.experimental.pipeline import Pipeline\n",
    "from neo4j_graphrag.schema import get_schema\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba595511",
   "metadata": {},
   "source": [
    "Reading all the pdf files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75f2ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folder_path = Path(r\"C:\\Users\\shant\\OneDrive\\Desktop\\GraphRAGresume\\input\")\n",
    "\n",
    "# Collect all PDF files in that folder\n",
    "pdf_files = list(folder_path.glob(\"*.pdf\"))\n",
    "print(pdf_files)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c4040f",
   "metadata": {},
   "source": [
    "Connecting to the driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e475bd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def run_kg_pipeline_with_auto_schema() -> None:\n",
    "    \"\"\"Run the SimpleKGPipeline with automatic schema extraction from a PDF file.\"\"\"\n",
    "\n",
    "    # Define Neo4j connection\n",
    "NEO4J_URI=\"neo4j+ssc://efea2c90.databases.neo4j.io\"\n",
    "NEO4J_USERNAME=\"neo4j\"\n",
    "NEO4J_PASSWORD=\"7V18VY7NXa1QQl06JD7_FONhdeqSap_7pUMBTgg-o3A\"\n",
    "NEO4J_DATABASE=\"neo4j\"\n",
    "AURA_INSTANCEID=\"efea2c90\"\n",
    "AURA_INSTANCENAME=\"Instance01\"\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    " \n",
    "AUTH = (NEO4J_USERNAME, NEO4J_PASSWORD)\n",
    "with GraphDatabase.driver(NEO4J_URI, auth=AUTH) as driver:\n",
    "    driver.verify_connectivity()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09980214",
   "metadata": {},
   "source": [
    "Initialising LLM ,Embedder and Driver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5339cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Define LLM parameters\n",
    "llm_model_params = {\n",
    "        \"max_tokens\": 2000,\n",
    "        \"response_format\": {\"type\": \"json_object\"},\n",
    "        \"temperature\": 0,  # Lower temperature for more consistent output\n",
    "    }\n",
    "\n",
    "    # Initialize the Neo4j driver\n",
    "driver = neo4j.GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
    "\n",
    "    # Create the LLM instance\n",
    "\n",
    "llm = AzureOpenAILLM(\n",
    "    #model_name=\"gpt-4o-intern\",\n",
    "    # model_name=\"gpt-4o\",  # This should match your Azure deployment name for the LLM\n",
    "    # Create the embedder instance\n",
    ")\n",
    "embedder = AzureOpenAIEmbeddings(\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9027c14",
   "metadata": {},
   "source": [
    "Indexing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5266707",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "        # Create a SimpleKGPipeline instance without providing a schema\n",
    "        # This will trigger automatic schema extraction\n",
    "kg_builder = SimpleKGPipeline(\n",
    "llm=llm,\n",
    "driver=driver,\n",
    "embedder=embedder,\n",
    "from_pdf=True,\n",
    ")\n",
    "for pdf_file in pdf_files:\n",
    "    print(f\"Processing: {pdf_file}\")\n",
    "    pdf_result=await kg_builder.run_async(file_path=str(pdf_file))\n",
    "    print(f\"Result: {pdf_result}\")\n",
    "    # Close connections\n",
    "#await llm.async_client.close()\n",
    "#driver.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd6a5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def main() -> None:\n",
    "    # Run the pipeline\n",
    "    await run_kg_pipeline_with_auto_schema()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    await(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c77b977",
   "metadata": {},
   "source": [
    "Creation of Indexes in Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3df914b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "from neo4j_graphrag.indexes import create_vector_index\n",
    "\n",
    "\n",
    "INDEX_NAME = \"vector-index-name\"\n",
    "NEO4J_URI=\"neo4j+ssc://efea2c90.databases.neo4j.io\"\n",
    "NEO4J_USERNAME=\"neo4j\"\n",
    "NEO4J_PASSWORD=\"7V18VY7NXa1QQl06JD7_FONhdeqSap_7pUMBTgg-o3A\"\n",
    "# Connect to the Neo4j database\n",
    "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
    "\n",
    "# Create the index\n",
    "res=create_vector_index(\n",
    "    driver,\n",
    "    INDEX_NAME,\n",
    "    label=\"Chunk\",\n",
    "    embedding_property=\"embedding\",\n",
    "    dimensions=1536,\n",
    "    similarity_fn=\"cosine\",\n",
    ")\n",
    "print(f\"Index created: {res}\")\n",
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fd8b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j_graphrag.schema import get_schema\n",
    "from neo4j import GraphDatabase\n",
    " \n",
    "schema = get_schema(driver, database=\"neo4j\")\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6945d1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_template = '''Answer the Question using the following Context. Only respond with information mentioned in the Context. Do not inject any speculative information not mentioned.\n",
    "\n",
    "# Question:\n",
    "{query_text}\n",
    "\n",
    "# Context:\n",
    "{context}\n",
    "\n",
    "# Answer:\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8a3d71",
   "metadata": {},
   "source": [
    "vector retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3e06ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j_graphrag.indexes import create_vector_index\n",
    "\n",
    "create_vector_index(driver, \n",
    "                    name=\"vector-index-name\", \n",
    "                    label=\"Chunk\", \n",
    "                    embedding_property=\"embedding\", \n",
    "                    dimensions=1536,  \n",
    "                    similarity_fn=\"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc4dd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j_graphrag.retrievers import VectorRetriever\n",
    "\n",
    "vector_retriever = VectorRetriever(\n",
    "   driver,\n",
    "   index_name=\"vector-index-name\",\n",
    "   embedder=embedder,\n",
    "   return_properties=[\"text\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565a4ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "vector_res = vector_retriever.get_search_results(query_text = \"CGPA of abhishek in Undergraduation ?\",top_k=5)\n",
    "for i in vector_res.records: print(\"====n\" + json.dumps(i.data(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e679b3a",
   "metadata": {},
   "source": [
    "VectorCypherRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa39e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j_graphrag.retrievers import VectorCypherRetriever\n",
    "\n",
    "vc_retriever = VectorCypherRetriever(\n",
    "    driver,\n",
    "    index_name=\"vector-index-name\",\n",
    "    embedder=embedder,\n",
    "    retrieval_query=\"\"\"\n",
    "//1) Go out 2-3 hops in the entity graph and get relationships\n",
    "WITH node AS chunk\n",
    "MATCH (chunk)<-[:FROM_CHUNK]-()-[relList:!FROM_CHUNK]-{1,2}()\n",
    "UNWIND relList AS rel\n",
    " \n",
    "//2) collect relationships and text chunks\n",
    "WITH collect(DISTINCT chunk) AS chunks,\n",
    " collect(DISTINCT rel) AS rels\n",
    " \n",
    "//3) format and return context\n",
    "RETURN '=== text ===n' + apoc.text.join([c in chunks | c.text], 'n---n') + 'nn=== kg_rels ===n' +\n",
    " apoc.text.join([r in rels | startNode(r).name + ' - ' + type(r) + '(' + coalesce(r.details, '') + ')' +  ' -> ' + endNode(r).name ], 'n---n') AS info\n",
    "\"\"\"\n",
    ")\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7c5f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "vc_res = vc_retriever.get_search_results(query_text = \"summarise me the resume of ALOK MISHRA?\", top_k=1)\n",
    "\n",
    "# print output\n",
    "kg_rel_pos = vc_res.records[0]['info'].find('nn=== kg_rels ===n')\n",
    "print(\"# Text Chunk Context:\")\n",
    "print(vc_res.records[0]['info'][:kg_rel_pos])\n",
    "print(\"# KG Context From Relationships:\")\n",
    "print(vc_res.records[0]['info'][kg_rel_pos:])\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7962552c",
   "metadata": {},
   "source": [
    "Text2Cypher Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763a8745",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neo4j\n",
    "from neo4j_graphrag.retrievers import Text2CypherRetriever\n",
    "\n",
    "\n",
    "llm_model_params = {\n",
    "        \"max_tokens\": 2000,\n",
    "        \"response_format\": {\"type\": \"text\"},\n",
    "        \"temperature\": 0,  # Lower temperature for more consistent output\n",
    "    }\n",
    "\n",
    "    # Initialize the Neo4j driver\n",
    "driver = neo4j.GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
    "\n",
    "    # Create the LLM instance\n",
    "\n",
    "llm = AzureOpenAILLM(\n",
    "    #model_name=\"gpt-4o-intern\",\n",
    "    # model_name=\"gpt-4o\",  # This should match your Azure deployment name for the LLM\n",
    "    model_name =\"gpt-4o-11-20\",  # This should match your Azure deployment name for the LLM\n",
    "    azure_endpoint=\"https://raginternaffine.openai.azure.com/\",  # update with your endpoint\n",
    "    api_version=\"2024-12-01-preview\",  # update appropriate version\n",
    "    api_key=\"9iApMYG4ac931NMjWX6cM0AMKhJKsC7Y6tDOPOSGAPSe7lypOGlZJQQJ99BGACMsfrFXJ3w3AAABACOGrjzw\",  # api_key is optional and can also be set with OPENAI_API_KEY env var\n",
    "    model_params=llm_model_params,\n",
    "    )\n",
    "# (Optional) Provide user input/query pairs for the LLM to use as examples\n",
    "examples = [\n",
    "\n",
    "    \"USER INPUT: 'Who all are skilled in vector databases?' QUERY: MATCH (p:Person)-[:DEMONSTRATES_SKILL]->(s:Skill) WHERE s.name =~ '(?i).*vector.*' RETURN p.name\"\n",
    "]\n",
    "\n",
    "with neo4j.GraphDatabase.driver(NEO4J_URI, auth=AUTH) as driver:\n",
    "    # Initialize the retriever\n",
    "    Text2Cypher_Retriever = Text2CypherRetriever(\n",
    "        driver,\n",
    "        llm=llm,\n",
    "        neo4j_schema=schema,\n",
    "        examples=examples,\n",
    "        neo4j_database='neo4j',\n",
    "    )\n",
    "query_text = \"summarise me the resume of Abhishek?\"\n",
    "ret=Text2Cypher_Retriever.search(query_text=query_text)\n",
    "    # print output\n",
    "print(ret)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bef2111",
   "metadata": {},
   "outputs": [],
   "source": [
    "Text2Cypher_Retriever_rag = GraphRAG(retriever=Text2Cypher_Retriever, llm=llm)\n",
    "\n",
    "# Query the graph\n",
    "query_text = \"give me information about work experience of Abhishek Nandgadkar?\"\n",
    "response = Text2Cypher_Retriever_rag.search(query_text=query_text)\n",
    "print(response.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e78001",
   "metadata": {},
   "source": [
    "Hybrid-Cypher Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1604e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j_graphrag.indexes import create_fulltext_index\n",
    "FULLTEXT_INDEX_NAME = \"fulltext_index\"\n",
    "\n",
    "driver = neo4j.GraphDatabase.driver(NEO4J_URI, auth=AUTH)\n",
    "create_fulltext_index(\n",
    "    driver, FULLTEXT_INDEX_NAME, label=\"Document\", node_properties=[\"textProperty\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d31cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j_graphrag.retrievers import HybridCypherRetriever\n",
    "llm_model_params = {\n",
    "        \"max_tokens\": 2000,\n",
    "        \"response_format\": {\"type\": \"text\"},\n",
    "        \"temperature\": 0,  # Lower temperature for more consistent output\n",
    "    }\n",
    "llm = AzureOpenAILLM(\n",
    "    #model_name=\"gpt-4o-intern\",\n",
    "    # model_name=\"gpt-4o\",  # This should match your Azure deployment name for the LLM\n",
    "    model_name =\"gpt-4o-11-20\",  # This should match your Azure deployment name for the LLM\n",
    "    azure_endpoint=\"https://raginternaffine.openai.azure.com/\",  # update with your endpoint\n",
    "    api_version=\"2024-12-01-preview\",  # update appropriate version\n",
    "    api_key=\"9iApMYG4ac931NMjWX6cM0AMKhJKsC7Y6tDOPOSGAPSe7lypOGlZJQQJ99BGACMsfrFXJ3w3AAABACOGrjzw\",  # api_key is optional and can also be set with OPENAI_API_KEY env var\n",
    "    model_params=llm_model_params,\n",
    "    )\n",
    "\n",
    "RETRIEVAL_QUERY = \"\"\"\n",
    "MATCH (p:Person)-[:DEMONSTRATES_SKILL]->(s:Skill)\n",
    "RETURN s.name AS skill,\n",
    "       count(DISTINCT p) AS person_count,\n",
    "       collect(DISTINCT p.name) AS persons\n",
    "ORDER BY person_count DESC;\n",
    "\"\"\"\n",
    "\n",
    "with neo4j.GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD)) as driver:\n",
    "    # Initialize the retriever\n",
    "    HybridCypher_Retriever = HybridCypherRetriever(\n",
    "        driver=driver,\n",
    "        vector_index_name='vector-index-name',\n",
    "        fulltext_index_name='fulltext_index',\n",
    "        embedder=embedder,\n",
    "        retrieval_query=RETRIEVAL_QUERY,\n",
    "        result_formatter=None,\n",
    "    )\n",
    "    # Perform the similarity search for a text query\n",
    "query_text = \"CGPA of Abhishek Nandgadkar?\"\n",
    "response = HybridCypher_Retriever.search(query_text=query_text, top_k=1)\n",
    "print(f\"Hybrid Cypher Response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0f9c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RAG pipeline\n",
    "HybridCypher_Retriever_rag = GraphRAG(retriever=HybridCypher_Retriever, llm=llm)\n",
    "\n",
    "# Query the graph\n",
    "query_text = \"Work experience of Abhishek Nandgadkar?\"\n",
    "response = HybridCypher_Retriever_rag.search(query_text=query_text, retriever_config={'top_k': 40})\n",
    "print(response.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e09b00",
   "metadata": {},
   "source": [
    "Hybrid Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557bb843",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j_graphrag.retrievers import HybridRetriever\n",
    "\n",
    "#INDEX_NAME = \"vector-index-name\"\n",
    "#FULLTEXT_INDEX_NAME = \"fulltext_index\"\n",
    "\n",
    "llm_model_params = {\n",
    "        \"max_tokens\": 2000,\n",
    "        #\"response_format\": {\"type\": \"json_object\"},\n",
    "        \"temperature\": 0,  # Lower temperature for more consistent output\n",
    "    }\n",
    "\n",
    "    # Initialize the Neo4j driver\n",
    "    # Create the LLM instance\n",
    "\n",
    "llm = AzureOpenAILLM(\n",
    "    #model_name=\"gpt-4o-intern\",\n",
    "    # model_name=\"gpt-4o\",  # This should match your Azure deployment name for the LLM\n",
    "    model_name =\"gpt-4o-11-20\",  # This should match your Azure deployment name for the LLM\n",
    "    azure_endpoint=\"https://raginternaffine.openai.azure.com/\",  # update with your endpoint\n",
    "    api_version=\"2024-12-01-preview\",  # update appropriate version\n",
    "    api_key=\"9iApMYG4ac931NMjWX6cM0AMKhJKsC7Y6tDOPOSGAPSe7lypOGlZJQQJ99BGACMsfrFXJ3w3AAABACOGrjzw\",  # api_key is optional and can also be set with OPENAI_API_KEY env var\n",
    "    model_params=llm_model_params,\n",
    "    )\n",
    "with neo4j.GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD)) as driver:\n",
    "    # Initialize the retriever\n",
    "    Hybrid_Retriever = HybridRetriever(\n",
    "        driver=driver,\n",
    "        vector_index_name=\"vector-index-name\",\n",
    "        fulltext_index_name=\"fulltext_index\",\n",
    "        embedder=embedder,\n",
    "    )\n",
    "\n",
    "    # Perform the similarity search for a text query\n",
    "    # (retrieve the top 5 most similar nodes)\n",
    "    #query_text = \"Who all have worked with vector Databases\"\n",
    "    #print(Hybrid_Retriever.search(query_text=query_text, top_k=5))\n",
    "    Hybrid_Retriever_rag = GraphRAG(retriever=Hybrid_Retriever, llm=llm)\n",
    "\n",
    "# Query the graph\n",
    "query_text = \"work experience of Abhishek Nandgadkar?\"\n",
    "response = Hybrid_Retriever_rag.search(query_text=query_text, retriever_config={'top_k': 44})\n",
    "print(response.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2afbc7",
   "metadata": {},
   "source": [
    "vector retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503f1e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the RAG pipeline\n",
    "vector_retriever_rag = GraphRAG(retriever=vector_retriever, llm=llm)\n",
    "# Query the graph\n",
    "# Give me a table of education details of every person?\n",
    "\n",
    "query_text = \"work experience of Abhishek Nandgadkar?\"\n",
    "response = vector_retriever_rag.search(query_text=query_text, retriever_config={\"top_k\": 1})\n",
    "\n",
    "print(response.answer)\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead4fbbf",
   "metadata": {},
   "source": [
    "Instantiate the rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136c2141",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j_graphrag.generation.prompts import RagTemplate\n",
    "from neo4j_graphrag.retrievers import VectorRetriever\n",
    "\n",
    "# Define the template as a string\n",
    "template_str = \"\"\"\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{query_text}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# Create the RagTemplate object\n",
    "rag_template = RagTemplate(\n",
    "    template=template_str,\n",
    "    expected_inputs=['query_text', 'context']\n",
    ")\n",
    "\n",
    "\n",
    "vector_retriever_rag  = GraphRAG(llm=llm, retriever=vector_retriever, prompt_template=rag_template)\n",
    "vector_cypher_retriever_rag = GraphRAG(llm=llm, retriever=vc_retriever, prompt_template=rag_template)\n",
    "Text2Cypher_Retriever_rag = GraphRAG(retriever=Text2Cypher_Retriever, llm=llm)\n",
    "HybridCypher_Retriever_rag = GraphRAG(retriever=HybridCypher_Retriever, llm=llm)\n",
    "Hybrid_Retriever_rag = GraphRAG(retriever=Hybrid_Retriever, llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f0a670",
   "metadata": {},
   "source": [
    "Different Query Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c132ca8",
   "metadata": {},
   "source": [
    "query responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03e4b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"List of people who know NLP?\"\n",
    "\n",
    "print(f\"Vector Response: n{ vector_retriever_rag.search(q, retriever_config={'top_k':5}).answer}\")\n",
    "print(\"n===========================n\")\n",
    "print(f\"Vector + Cypher Response: n{vector_cypher_retriever_rag.search(q, retriever_config={'top_k':5}).answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c85618",
   "metadata": {},
   "source": [
    "vector-cypher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae48ce78",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_cypher_retriever_rag = GraphRAG(llm=llm, retriever=vc_retriever)\n",
    "\n",
    "query_text = \"List of people who know NLP?\"\n",
    "\n",
    "vc_rag_result = vector_cypher_retriever_rag.search(query_text=query_text, retriever_config={'top_k': 5}, return_context=True)\n",
    "\n",
    "print(f\"Vector + Cypher Response: n{vc_rag_result.answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750f23d4",
   "metadata": {},
   "source": [
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8d32d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_retriever_rag  = GraphRAG(llm=llm, retriever=vector_retriever)\n",
    "\n",
    "query_text = \"List of people who know NLP?\"\n",
    "v_rag_result = vector_retriever_rag.search(query_text=query_text, retriever_config={'top_k': 5}, return_context=True)\n",
    "print(\"n===========================n\")\n",
    "print(f\"Vector Response: {v_rag_result.answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06b7dea",
   "metadata": {},
   "source": [
    "hybrid-retriever rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9da9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hybrid_Retriever_rag = GraphRAG(retriever=Hybrid_Retriever, llm=llm)\n",
    "\n",
    "query_text = \"List of people who know NLP?\"\n",
    "response = Hybrid_Retriever_rag.search(query_text=query_text, retriever_config={'top_k': 44})\n",
    "print(response.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e17bb2d",
   "metadata": {},
   "source": [
    "hybrid-cypher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189478d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "HybridCypher_Retriever_rag = GraphRAG(retriever=HybridCypher_Retriever, llm=llm)\n",
    "\n",
    "query_text = \"List of people who know NLP?\"\n",
    "response=HybridCypher_Retriever_rag.search(query_text=query_text)\n",
    "print(response.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffeb36ed",
   "metadata": {},
   "source": [
    "text2cypher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e1cc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Text2Cypher_Retriever_rag = GraphRAG(retriever=Text2Cypher_Retriever, llm=llm)\n",
    "\n",
    "query_text = \"List of people who know NLP?\"\n",
    "response=Text2Cypher_Retriever_rag.search(query_text=query_text)\n",
    "    # print output\n",
    "print(response.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a059a6ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8ab1cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89d73c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6077ba4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571dd2a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
